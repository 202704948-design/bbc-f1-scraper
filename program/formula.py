import requests
from bs4 import BeautifulSoup
import csv
import re
import os  # ç¬¬ä¸€æ­¥ï¼šä¸€å®šè¦å¯¼å…¥è¿™ä¸ªå·¥å…·ç®±ï¼

# ç¬¬äºŒæ­¥ï¼šå…ˆå®šä¹‰åå­—ï¼Œå†ä½¿ç”¨å®ƒ
url = "https://www.bbc.com/sport/formula1"
headers = {'User-Agent': 'Mozilla/5.0'}
filename = 'f1_news_perfect.csv'  # <--- æŠŠå®ƒæŒªåˆ°è¿™é‡Œï¼

# ç¬¬ä¸‰æ­¥ï¼šè¿™æ—¶å€™ Python å°±è®¤è¯† filename äº†
old_titles = []
if os.path.exists(filename):
    with open(filename, 'r', encoding='utf-8-sig') as f:
        reader = csv.reader(f)
        try:
            next(reader)  # è·³è¿‡è¡¨å¤´
            for row in reader:
                if len(row) > 2:  # ç¡®ä¿è¿™è¡Œæœ‰æ•°æ®
                    old_titles.append(row[2]) # å‡è®¾æ ‡é¢˜åœ¨ç¬¬ä¸‰åˆ—
        except StopIteration:
            pass # å¦‚æœæ–‡ä»¶æ˜¯ç©ºçš„ï¼Œå°±è·³è¿‡

response = requests.get(url, headers=headers)

# ğŸšª åœ¨è¿™é‡Œå»ºç«‹å®‰å…¨é—¨
if response.status_code == 200:
    print("æˆåŠŸè¿æ¥åˆ° BBCï¼æ­£åœ¨å¼€å§‹ç¿»è¯‘ç½‘é¡µ...")
    soup = BeautifulSoup(response.text, "html.parser")
    # ... è¿™é‡Œæ”¾ä½ ä¹‹åçš„ boxes æŠ“å–ã€å¾ªç¯å’Œ CSV å†™å…¥ä»£ç  ...
    # æ³¨æ„ï¼šæ‰€æœ‰åœ¨ if é‡Œé¢çš„ä»£ç éƒ½è¦å‘å³ç¼©è¿›ï¼ˆIndentï¼‰
else:
    # å¦‚æœé—¨æ²¡å¼€ï¼ˆæ¯”å¦‚è¿”å›äº† 404 æˆ– 403ï¼‰
    print(f"ç³Ÿç³•ï¼Œé—¨æ²¡å¼€ï¼é”™è¯¯ä»£ç æ˜¯ï¼š{response.status_code}")

boxes = soup.find_all("div", attrs={"data-testid": "promo"})

if not boxes:
    print("è­¦æŠ¥ï¼æ²¡æ‰¾åˆ°ä»»ä½•æ–°é—»ç›’å­ï¼Œå¯èƒ½æ˜¯ç½‘é¡µæ”¹ç‰ˆäº†ï¼")
else:
    print(f"å¤ªæ£’äº†ï¼ŒæŠ“åˆ°äº† {len(boxes)} æ¡æ–°é—»ï¼")
    # å¼€å§‹ä½ çš„ for å¾ªç¯...

with open(filename, 'w', encoding='utf-8-sig', newline='') as f:
    writer = csv.writer(f)
    writer.writerow(['å‘å¸ƒæ—¶é—´', 'ç±»å‹/æ¥æº', 'æ ‡é¢˜', 'ç®€è®¯'])
    
    for box in boxes:
        # --- A. æå–æ ‡é¢˜ ---
        # å¯»æ‰¾å¸¦æœ‰ç‰¹å®šç±»åçš„æ ‡é¢˜ï¼Œé¿å…è¯¯æŠ“
        title_tag = box.find("a")
        title = title_tag.get_text(strip=True) if title_tag else "æ— æ ‡é¢˜"
        
        # --- B. æå–ç®€è®¯ ---
        # ğŸ’¡ æ”¹è¿›ï¼šæŒ‡å®šç±»å ssrcss-1q0x1qg-Paragraphï¼Œé¿å…æŠ“åˆ°æ ‡é¢˜é‡Œçš„æ–‡å­—
        summary_tag = box.find("p", class_="ssrcss-1q0x1qg-Paragraph")
        summary = summary_tag.get_text(strip=True) if summary_tag else "ï¼ˆæ­¤æ¡ä¸ºå¿«è®¯/è§†é¢‘ï¼‰"
        
        # å¦‚æœç®€è®¯å’Œæ ‡é¢˜ä¸€æ¨¡ä¸€æ ·ï¼Œè¯´æ˜æŠ“é”™äº†ï¼Œè®¾ä¸ºè¡¥å……è¯´æ˜
        if summary == title:
            summary = "ï¼ˆç‚¹å‡»è¿›å…¥æŸ¥çœ‹è¯¦æƒ…ï¼‰"
            
        # --- C. ç²¾ç»†åŒ–åˆ†æ‹£å…ƒæ•°æ® ---
        metadata_spans = box.find_all("span", class_="ssrcss-61mhsj-MetadataText e4wm5bw1")
        
        post_time = "" # 1. é»˜è®¤è®¾ç½®ä¸ºç©ºï¼Œä¸å†æ˜¾ç¤ºâ€œä¸“é¢˜/æ±‡æ€»â€
        other_info = []
        
        # æ‰©å±•æ—¶é—´å…³é”®è¯ï¼ŒåŒ…å«æœˆä»½å’Œé•¿æ•ˆè§†é¢‘æè¿°
        time_keywords = [
            "posted", "ago", "hours", "mins", "days", "year", "available",
            "jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"
        ]
        
        for span in metadata_spans:
            full_text = span.get_text(strip=True)
            text_lower = full_text.lower()
            
            # è¿‡æ»¤å¹²æ‰°é¡¹
            if "comment" in text_lower or "follow" in text_lower:
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¶é—´ç›¸å…³çš„å…³é”®è¯
            is_time = any(word in text_lower for word in time_keywords)
            
            if is_time:
                # 2. å¦‚æœæ˜¯æ—¶é—´ï¼Œä¼˜å…ˆå–â€œéšèº«â€çš„å¹²å‡€ç‰ˆæœ¬ï¼ˆå¦‚ 16 Februaryï¼‰
                hidden_tag = span.find("span", class_="visually-hidden")
                if hidden_tag:
                    post_time = hidden_tag.get_text(strip=True)
                else:
                    # å¦‚æœæ²¡æœ‰éšèº«æ ‡ç­¾ï¼Œä¸ºäº†é˜²æ­¢ 16 February16 Feb è¿™ç§é‡å¤ï¼Œåªå–å‰åŠéƒ¨åˆ†
                    # è¿™æ˜¯ä¸€ä¸ªå°æŠ€å·§ï¼šé€šå¸¸é‡å¤çš„éƒ¨åˆ†é•¿åº¦è¾ƒçŸ­
                    post_time = full_text[:len(full_text)//2] if len(full_text) > 10 else full_text
            else:
                # 3. å‰©ä¸‹çš„ï¼ˆå¦‚ Formula 1, BBC World Serviceï¼‰æ”¾å…¥ç±»å‹æ 
                if full_text and not full_text.isdigit():
                    other_info.append(full_text)
        
        # æ•´ç†ç±»å‹æ¥æº
        category_source = " | ".join(list(dict.fromkeys(other_info))) if other_info else "Formula 1"
        
        
        writer.writerow([post_time, category_source, title, summary])

print(f"âœ… ä»»åŠ¡å®Œæˆï¼è¯·æ£€æŸ¥æœ€æ–°çš„ï¼š{filename}")
# æ ¸å¿ƒåˆ†æ‹£é€»è¾‘ï¼šé€šè¿‡å…³é”®è¯è¯†åˆ«æ—¶é—´ï¼Œå¹¶åˆ©ç”¨å­—ç¬¦ä¸²åˆ‡ç‰‡å’Œå­—å…¸å»é‡æ¸…æ´—æ•°æ®ã€‚

new_stories = []
for box in boxes:
    # æå–æ ‡é¢˜ title ...
    if title not in existing_titles:
        new_stories.append({"title": title, "link": link})

# 3. åªæœ‰å½“ new_stories ä¸ä¸ºç©ºæ—¶ï¼Œæ‰æ‰§è¡Œå†™å…¥å’Œå‘é‚®ä»¶
if new_stories:
    print(f"æ£€æµ‹åˆ° {len(new_stories)} æ¡æ–°æ¶ˆæ¯ï¼Œå‡†å¤‡å‘é€é‚®ä»¶...")
    
    # æ„é€ é‚®ä»¶å†…å®¹
    email_content = "æœ€æ–°å›´åœºæ¶ˆæ¯ï¼š\n\n"
    for item in new_stories:
        email_content += f"ã€{item['title']}ã€‘\né“¾æ¥ï¼š{item['link']}\n\n"

    # å‘é€é‚®ä»¶é€»è¾‘
    msg = MIMEText(email_content)
    msg['Subject'] = 'ğŸï¸ F1 å›´åœºæœ€æ–°æ¶ˆæ¯æé†’'
    msg['From'] = os.getenv('EMAIL_USER')
    msg['To'] = "ä½ çš„æ¥æ”¶é‚®ç®±@example.com"

    with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:
        server.login(os.getenv('EMAIL_USER'), os.getenv('EMAIL_PASS'))
        server.send_message(msg)
    
    # æœ€åå†æ›´æ–° CSV æ–‡ä»¶ï¼ˆè¦†ç›–æ—§çš„ï¼‰
    # ... ä¹‹å‰çš„å†™å…¥é€»è¾‘ ...
else:
    print("æ²¡æœ‰æ–°å†…å®¹ï¼Œè·³è¿‡æé†’ã€‚")