import requests
from bs4 import BeautifulSoup
import csv
import re # å¯¼å…¥æ­£åˆ™è¡¨è¾¾å¼ï¼Œç”¨äºç²¾å‡†è¯†åˆ«æ•°å­—

url = "https://www.bbc.com/sport/formula1"
headers = {'User-Agent': 'Mozilla/5.0'}
filename = 'f1_news_perfect.csv'

response = requests.get(url, headers=headers)
soup = BeautifulSoup(response.text, "html.parser")

boxes = soup.find_all("div", attrs={"data-testid": "promo"})
print(f"ğŸ•µï¸â€â™‚ï¸ æœç´¢å®Œæˆï¼Œä¸€å…±æŠ“åˆ°äº† {len(boxes)} æ¡æ–°é—»ï¼")

with open(filename, 'w', encoding='utf-8-sig', newline='') as f:
    writer = csv.writer(f)
    writer.writerow(['å‘å¸ƒæ—¶é—´', 'ç±»å‹/æ¥æº', 'æ ‡é¢˜', 'ç®€è®¯'])
    
    for box in boxes:
        # --- A. æå–æ ‡é¢˜ ---
        # å¯»æ‰¾å¸¦æœ‰ç‰¹å®šç±»åçš„æ ‡é¢˜ï¼Œé¿å…è¯¯æŠ“
        title_tag = box.find("a")
        title = title_tag.get_text(strip=True) if title_tag else "æ— æ ‡é¢˜"
        
        # --- B. æå–ç®€è®¯ ---
        # ğŸ’¡ æ”¹è¿›ï¼šæŒ‡å®šç±»å ssrcss-1q0x1qg-Paragraphï¼Œé¿å…æŠ“åˆ°æ ‡é¢˜é‡Œçš„æ–‡å­—
        summary_tag = box.find("p", class_="ssrcss-1q0x1qg-Paragraph")
        summary = summary_tag.get_text(strip=True) if summary_tag else "ï¼ˆæ­¤æ¡ä¸ºå¿«è®¯/è§†é¢‘ï¼‰"
        
        # å¦‚æœç®€è®¯å’Œæ ‡é¢˜ä¸€æ¨¡ä¸€æ ·ï¼Œè¯´æ˜æŠ“é”™äº†ï¼Œè®¾ä¸ºè¡¥å……è¯´æ˜
        if summary == title:
            summary = "ï¼ˆç‚¹å‡»è¿›å…¥æŸ¥çœ‹è¯¦æƒ…ï¼‰"
            
        # --- C. ç²¾ç»†åŒ–åˆ†æ‹£å…ƒæ•°æ® ---
        metadata_spans = box.find_all("span", class_="ssrcss-61mhsj-MetadataText e4wm5bw1")
        
        post_time = "" # 1. é»˜è®¤è®¾ç½®ä¸ºç©ºï¼Œä¸å†æ˜¾ç¤ºâ€œä¸“é¢˜/æ±‡æ€»â€
        other_info = []
        
        # æ‰©å±•æ—¶é—´å…³é”®è¯ï¼ŒåŒ…å«æœˆä»½å’Œé•¿æ•ˆè§†é¢‘æè¿°
        time_keywords = [
            "posted", "ago", "hours", "mins", "days", "year", "available",
            "jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"
        ]
        
        for span in metadata_spans:
            full_text = span.get_text(strip=True)
            text_lower = full_text.lower()
            
            # è¿‡æ»¤å¹²æ‰°é¡¹
            if "comment" in text_lower or "follow" in text_lower:
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¶é—´ç›¸å…³çš„å…³é”®è¯
            is_time = any(word in text_lower for word in time_keywords)
            
            if is_time:
                # 2. å¦‚æœæ˜¯æ—¶é—´ï¼Œä¼˜å…ˆå–â€œéšèº«â€çš„å¹²å‡€ç‰ˆæœ¬ï¼ˆå¦‚ 16 Februaryï¼‰
                hidden_tag = span.find("span", class_="visually-hidden")
                if hidden_tag:
                    post_time = hidden_tag.get_text(strip=True)
                else:
                    # å¦‚æœæ²¡æœ‰éšèº«æ ‡ç­¾ï¼Œä¸ºäº†é˜²æ­¢ 16 February16 Feb è¿™ç§é‡å¤ï¼Œåªå–å‰åŠéƒ¨åˆ†
                    # è¿™æ˜¯ä¸€ä¸ªå°æŠ€å·§ï¼šé€šå¸¸é‡å¤çš„éƒ¨åˆ†é•¿åº¦è¾ƒçŸ­
                    post_time = full_text[:len(full_text)//2] if len(full_text) > 10 else full_text
            else:
                # 3. å‰©ä¸‹çš„ï¼ˆå¦‚ Formula 1, BBC World Serviceï¼‰æ”¾å…¥ç±»å‹æ 
                if full_text and not full_text.isdigit():
                    other_info.append(full_text)
        
        # æ•´ç†ç±»å‹æ¥æº
        category_source = " | ".join(list(dict.fromkeys(other_info))) if other_info else "Formula 1"
        
        
        writer.writerow([post_time, category_source, title, summary])

print(f"âœ… ä»»åŠ¡å®Œæˆï¼è¯·æ£€æŸ¥æœ€æ–°çš„ï¼š{filename}")